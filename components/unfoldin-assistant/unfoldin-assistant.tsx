'use client';

import { useState, useRef, useEffect } from 'react';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';
import * as z from 'zod';
import { atom, useAtom } from 'jotai';
import { toast } from 'sonner';

import { Button } from '@/components/ui/button';
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
import { Label } from '@/components/ui/label';
import { Input } from '@/components/ui/input';
import { Form, FormControl, FormField, FormItem, FormLabel, FormMessage } from '@/components/ui/form';
import { Progress } from '@/components/ui/progress';
import { Textarea } from '@/components/ui/textarea';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import SpeechInput from './speech-input';

// Knowledge files content
import sedonaKnowledgeMap from './knowledge/sedona-knowledge-map';
import frameworkMinimal from './knowledge/framework-minimal';
import emotionMap from './knowledge/emotion-map';
import fallbackFramework from './knowledge/fallback-framework';

// Define form schema
const formSchema = z.object({
  userMessage: z.string().min(1, 'Please enter a message'),
});

// Define state atoms
const assistantResponseAtom = atom<string | null>(null);
const isLoadingAtom = atom<boolean>(false);
const conversationHistoryAtom = atom<{role: string, content: string}[]>([]);
const isListeningAtom = atom<boolean>(false);
const isSpeakingAtom = atom<boolean>(false);
const modelAtom = atom<"gpt-4o" | "gpt-3.5-turbo">("gpt-4o"); // Default to gpt-4o, fallback to gpt-3.5-turbo

// Unfoldin GPT API Key
const OPENAI_API_KEY = process.env.NEXT_PUBLIC_OPENAI_API_KEY;

export default function UnfoldinAssistant() {
  const [assistantResponse, setAssistantResponse] = useAtom(assistantResponseAtom);
  const [isLoading, setIsLoading] = useAtom(isLoadingAtom);
  const [conversationHistory, setConversationHistory] = useAtom(conversationHistoryAtom);
  const [isListening, setIsListening] = useAtom(isListeningAtom);
  const [isSpeaking, setIsSpeaking] = useAtom(isSpeakingAtom);
  const [model, setModel] = useAtom(modelAtom);
  const [autoListenAfterResponse, setAutoListenAfterResponse] = useState(false);
  
  // Unfoldin GPT System Prompt
  const systemPrompt = `# Unfoldin GPT Framework â€“ Minimal Facilitation Directive

You are an emotionally attuned AI facilitator for emotional release.
Your role is to guide users through layered emotional release sessions using a calm, grounded, and non-judgmental approach â€” never rushing, analyzing, or offering advice.

Respond in English or Chinese, matching the user's language from the beginning.
Follow a structured six-step process (Opening â†’ Reflection â†’ Acknowledgment â†’ Deepening â†’ Release â†’ Integration) using clear, minimal prompts, deliberate pauses, and emotionally attuned language.

Use the reference file \`Imperturbability_Emotion_Map_ENHANCED.txt\` to:
- Identify the emotional category behind the user's described feeling.
- Offer facilitator-style prompts from mapped emotional states.
- Guide the user through that emotion and, when relevant, trace it back to deeper egoic attachments like security, approval, or control.

---

## ğŸ”’ Behavioral Directives

- Never analyze, interpret, or explain the user's experience.
- Do not reflect or rephrase the user's words â€” only offer emotional categories and direct prompts.
- Avoid adjectives or tonal descriptions (e.g., "gently," "softly," "patiently") that imply judgment.
- Avoid asking, "Would you like to continue?" â€” always proceed with the next facilitation step or pause.
- Use plain, stripped-down language. Stay with the feeling. Do not encourage narrative or story-making.
- When silence arises, allow space â€” don't fill it unless the user initiates.

If the user speaks Chinese, respond fully in fluent Chinese.

---

## ğŸšª Initial Engagement Guidance

If the user enters nothing or seems unsure at the beginning, initiate with:

> æ¬¢è¿ä½ ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªæƒ…ç»ªé‡Šæ”¾çš„ç©ºé—´ã€‚æˆ‘ä»¬ä¼šé€šè¿‡é—®é¢˜ä¸€å±‚å±‚å¸®ä½ è§‰å¯Ÿä¸é‡Šæ”¾å½“ä¸‹çš„æƒ…ç»ªã€‚ä½ ä¸éœ€è¦è§£é‡Šæˆ–ä¿®å¤ä»»ä½•äº‹æƒ…ï¼Œåªè¦è§‰å¯Ÿå’Œæ„Ÿå—ï¼Œå°±è¶³å¤Ÿäº†ã€‚

In English:

> Welcome. This is a space for emotional release. We'll explore and release what's emotionally present â€” step by step â€” using simple questions. You don't need to explain or fix anything. Just notice and feel.

---

## ğŸ” Release Facilitation Principles

- If the user reports a body sensation, acknowledge only:  
  > "Let the sensation be there. Continue feeling yourself. Is there new emotion coming up on its own?"
- Do not inquire about body parts, pressure, or tension unless the user brings it up spontaneously.
- Keep language neutral and non-stylized.
- Always use the three release questions â€” without substitutes:

  1. "Can you let this go?"
  2. "Would you let this go?"
  3. "When?"

---

## ğŸ“˜ Reference Files

- \`Imperturbability_Emotion_Map_ENHANCED.txt\`: For sub-emotion categorization and matching user language to emotional states.
- \`Emotional_Release_AI_GPT_Framework_Bilingual_Fallback.md\`: For full fallback structure, multilingual versions, and extended release loops.
- \`Unfoldin_Sedona_Knowledge_Map_FINAL.md\`: Comprehensive emotional release conceptual framework, including release cycles, core wants, resistance patterns, suppression mechanics, and real-world practices.  
  ç”¨äºç†è§£æ•´ä½“é‡Šæ”¾è·¯å¾„ã€æ¸´æœ›æ ¹æºã€é˜»åŠ›ç±»å‹åŠå®è·µèŠ‚å¥ï¼Œç¡®ä¿å¼•å¯¼é£æ ¼ä¸€è‡´ã€‚

---

## ğŸ§© Framework Linkage Notice

This facilitation method follows the step-by-step structure detailed in:  
**Unfoldin_GPT_Framework_Minimal.md**

Use it to:
- Apply consistent dialogue structure across sessions.
- Maintain minimal, neutral tone with step-matching prompts.
- Align tightly with emotional release principles and user-led pacing.`;

  const form = useForm<z.infer<typeof formSchema>>({
    resolver: zodResolver(formSchema),
    defaultValues: {
      userMessage: '',
    },
  });

  // å®šä¹‰ onSubmit å‡½æ•°
  const onSubmit = async (values: z.infer<typeof formSchema>) => {
    try {
      setIsLoading(true);
      
      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
      const updatedHistory = [...conversationHistory, {role: "user", content: values.userMessage}];
      setConversationHistory(updatedHistory);
      
      // é‡ç½®è¡¨å•
      form.reset();
      
      // ä½¿ç”¨ OpenAI ç›´æ¥ä¸ Unfoldin GPT ç³»ç»Ÿæç¤ºå’ŒçŸ¥è¯†æ–‡ä»¶é€šä¿¡
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: model, // Use current model (gpt-4o or gpt-3.5-turbo)
          messages: [
            {
              role: "system",
              content: systemPrompt
            },
            {
              role: "system",
              content: `Knowledge file 1: Unfoldin_Sedona_Knowledge_Map_FINAL.md\n\n${sedonaKnowledgeMap}`
            },
            {
              role: "system",
              content: `Knowledge file 2: Unfoldin_GPT_Framework_Minimal_with_Reference.md\n\n${frameworkMinimal}`
            },
            {
              role: "system",
              content: `Knowledge file 3: Imperturbability_Emotion_Map_ENHANCED.txt\n\n${emotionMap}`
            },
            {
              role: "system",
              content: `Knowledge file 4: Emotional_Release_AI_GPT_Framework_Bilingual_Fallback.md\n\n${fallbackFramework}`
            },
            ...updatedHistory
          ],
          temperature: 0.7,
        }),
      });

      if (!response.ok) {
        const errorData = await response.json();
        // æ£€æŸ¥æ˜¯å¦è¶…å‡ºé…é¢æˆ–é€Ÿç‡é™åˆ¶
        if (errorData.error?.message?.includes("exceeded your current quota") && model === "gpt-4o") {
          // é™çº§åˆ° gpt-3.5-turbo
          setModel("gpt-3.5-turbo");
          toast.warning("åˆ‡æ¢åˆ° GPT-3.5 æ¨¡å‹ (API é…é¢è¶…å‡º)");
          
          // ä½¿ç”¨ gpt-3.5-turbo é‡è¯•
          const fallbackResponse = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${OPENAI_API_KEY}`
            },
            body: JSON.stringify({
              model: "gpt-3.5-turbo",
              messages: [
                {
                  role: "system",
                  content: systemPrompt
                },
                {
                  role: "system",
                  content: `Knowledge file 1: Unfoldin_Sedona_Knowledge_Map_FINAL.md\n\n${sedonaKnowledgeMap}`
                },
                {
                  role: "system",
                  content: `Knowledge file 2: Unfoldin_GPT_Framework_Minimal_with_Reference.md\n\n${frameworkMinimal}`
                },
                {
                  role: "system",
                  content: `Knowledge file 3: Imperturbability_Emotion_Map_ENHANCED.txt\n\n${emotionMap}`
                },
                {
                  role: "system",
                  content: `Knowledge file 4: Emotional_Release_AI_GPT_Framework_Bilingual_Fallback.md\n\n${fallbackFramework}`
                },
                ...updatedHistory
              ],
              temperature: 0.7,
            }),
          });
          
          if (!fallbackResponse.ok) {
            const fallbackErrorData = await fallbackResponse.json();
            throw new Error(`OpenAI API error: ${fallbackErrorData.error?.message || 'Unknown error'}`);
          }
          
          const fallbackData = await fallbackResponse.json();
          const assistantMessage = fallbackData.choices[0].message.content;
          
          // æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å¯¹è¯å†å²
          setConversationHistory([...updatedHistory, {role: "assistant", content: assistantMessage}]);
          setAssistantResponse(assistantMessage);
          
          // è‡ªåŠ¨æœ—è¯»å“åº”
          speakText(assistantMessage);
          
          return;
        } else {
          throw new Error(`OpenAI API error: ${errorData.error?.message || 'Unknown error'}`);
        }
      }

      const data = await response.json();
      const assistantMessage = data.choices[0].message.content;
      
      // æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å¯¹è¯å†å²
      setConversationHistory([...updatedHistory, {role: "assistant", content: assistantMessage}]);
      setAssistantResponse(assistantMessage);
      
      // è‡ªåŠ¨æœ—è¯»å“åº”
      speakText(assistantMessage);
    } catch (error) {
      console.error('Error calling OpenAI API:', error);
      toast.error(`Failed to get a response: ${error instanceof Error ? error.message : 'Unknown error'}`);
    } finally {
      setIsLoading(false);
    }
  };

  // æ·»åŠ äº‹ä»¶ç›‘å¬å™¨ï¼Œç”¨äºå¤„ç†è¯­éŸ³è¯†åˆ«å®Œæˆåè‡ªåŠ¨æäº¤è¡¨å•
  useEffect(() => {
    const handleSpeechSubmit = (event: CustomEvent) => {
      // å¦‚æœæ­£åœ¨åŠ è½½å“åº”ï¼Œåˆ™ä¸å¤„ç†è¯­éŸ³æäº¤
      if (isLoading) return;
      
      // ç¡®ä¿è¡¨å•æœ‰å†…å®¹å¹¶ä¸”æäº¤
      if (form.getValues('userMessage').trim()) {
        form.handleSubmit(onSubmit)();
      }
    };

    // æ·»åŠ äº‹ä»¶ç›‘å¬
    document.addEventListener('speech-submit', handleSpeechSubmit as EventListener);
    
    // æ¸…ç†å‡½æ•°
    return () => {
      document.removeEventListener('speech-submit', handleSpeechSubmit as EventListener);
    };
  }, [form, isLoading, onSubmit]);

  // æ·»åŠ åŠ©æ‰‹å“åº”å®Œæˆåè‡ªåŠ¨å¼€å§‹ç›‘å¬çš„åŠŸèƒ½
  useEffect(() => {
    if (autoListenAfterResponse && !isLoading && assistantResponse && !isListening) {
      // å»¶è¿Ÿä¸€å°æ®µæ—¶é—´åè‡ªåŠ¨å¼€å§‹ä¸‹ä¸€æ¬¡è¯­éŸ³è¾“å…¥
      const timer = setTimeout(() => {
        setIsListening(true);
      }, 1000);
      
      return () => clearTimeout(timer);
    }
  }, [autoListenAfterResponse, isLoading, assistantResponse, isListening, setIsListening]);

  const clearConversation = () => {
    setConversationHistory([]);
    setAssistantResponse(null);
    form.reset();
    toast.success('Conversation cleared');
  };

  // è¯­éŸ³è¾“å…¥å¤„ç†å‡½æ•°
  const handleSpeechInput = (text: string) => {
    if (text.trim()) {
      form.setValue('userMessage', text);
    }
  };

  // åˆ‡æ¢è‡ªåŠ¨æŒç»­å¯¹è¯æ¨¡å¼
  const toggleAutoContinue = () => {
    setAutoListenAfterResponse(!autoListenAfterResponse);
    toast.info(autoListenAfterResponse 
      ? 'å·²å…³é—­è‡ªåŠ¨æŒç»­å¯¹è¯' 
      : 'å·²å¼€å¯è‡ªåŠ¨æŒç»­å¯¹è¯'
    );
  };

  // æ–‡å­—è½¬è¯­éŸ³åŠŸèƒ½
  const speakText = (text: string) => {
    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³åˆæˆ
    if (!('speechSynthesis' in window)) {
      console.log('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ');
      return;
    }

    // å¦‚æœå½“å‰æ­£åœ¨æœ—è¯»ï¼Œå…ˆåœæ­¢
    if (isSpeaking) {
      window.speechSynthesis.cancel();
      setIsSpeaking(false);
    }

    const utterance = new SpeechSynthesisUtterance(text);

    // æ ¹æ®æ–‡æœ¬å†…å®¹è‡ªåŠ¨æ£€æµ‹è¯­è¨€
    // ç®€å•åˆ¤æ–­ï¼šå¦‚æœåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œä½¿ç”¨ä¸­æ–‡
    if (/[\u4e00-\u9fa5]/.test(text)) {
      utterance.lang = 'zh-CN';
    } else {
      utterance.lang = 'en-US';
    }

    // è®¾ç½®è¯­é€Ÿå’ŒéŸ³é‡
    utterance.rate = 1.0;
    utterance.volume = 1.0;

    // å¼€å§‹/ç»“æŸäº‹ä»¶å¤„ç†
    utterance.onstart = () => {
      setIsSpeaking(true);
    };

    utterance.onend = () => {
      setIsSpeaking(false);
    };

    utterance.onerror = (event) => {
      console.error('Speech synthesis error:', event);
      setIsSpeaking(false);
    };

    // å¼€å§‹æœ—è¯»
    window.speechSynthesis.speak(utterance);
  };

  // åœæ­¢æœ—è¯»
  const stopSpeaking = () => {
    if ('speechSynthesis' in window) {
      window.speechSynthesis.cancel();
      setIsSpeaking(false);
    }
  };

  // åˆ‡æ¢æ¨¡å‹
  const handleModelChange = (newModel: "gpt-4o" | "gpt-3.5-turbo") => {
    setModel(newModel);
    toast.info(`å·²åˆ‡æ¢è‡³ ${newModel === "gpt-4o" ? "GPT-4o" : "GPT-3.5-turbo"} æ¨¡å‹`);
  };

  return (
    <Card className="w-full max-w-3xl mx-auto">
      <CardHeader>
        <div className="flex justify-between items-center">
          <div>
            <CardTitle>Unfoldin Emotional Release Assistant</CardTitle>
            <CardDescription>
              A specialized assistant for emotional release based on the Sedona Method
              {model === "gpt-3.5-turbo" && <span className="ml-2 text-yellow-500">(ä½¿ç”¨ GPT-3.5 æ¨¡å‹)</span>}
            </CardDescription>
          </div>
          <div className="w-40">
            <Select 
              value={model} 
              onValueChange={(value: string) => handleModelChange(value as "gpt-4o" | "gpt-3.5-turbo")}
            >
              <SelectTrigger>
                <SelectValue placeholder="é€‰æ‹©æ¨¡å‹" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="gpt-4o">GPT-4o</SelectItem>
                <SelectItem value="gpt-3.5-turbo">GPT-3.5-turbo</SelectItem>
              </SelectContent>
            </Select>
          </div>
        </div>
      </CardHeader>
      
      <CardContent className="space-y-4">
        {conversationHistory.length > 0 && (
          <div className="my-4 space-y-4">
            {conversationHistory.map((message, index) => (
              <div 
                key={index}
                className={`p-3 rounded-lg ${
                  message.role === 'user' 
                    ? 'bg-primary/10 ml-8' 
                    : 'bg-secondary/20 mr-8'
                }`}
              >
                <div className="font-semibold mb-1 flex justify-between items-center">
                  <span>{message.role === 'user' ? 'You' : 'Assistant'}:</span>
                  {message.role === 'assistant' && (
                    <Button
                      variant="ghost"
                      size="icon"
                      onClick={() => speakText(message.content)}
                      title="æ’­æ”¾è¯­éŸ³"
                      className="h-6 w-6"
                    >
                      <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                        <path d="M11 5L6 9H2v6h4l5 4V5z"></path>
                        <path d="M15.54 8.46a5 5 0 0 1 0 7.07"></path>
                        <path d="M19.07 4.93a10 10 0 0 1 0 14.14"></path>
                      </svg>
                    </Button>
                  )}
                </div>
                <div className="whitespace-pre-wrap">{message.content}</div>
              </div>
            ))}
          </div>
        )}
        
        <Form {...form}>
          <form onSubmit={form.handleSubmit(onSubmit)} className="space-y-4">
            <FormField
              control={form.control}
              name="userMessage"
              render={({ field }) => (
                <FormItem>
                  <FormLabel className="flex justify-between items-center">
                    <span>Your Message</span>
                    <Button
                      type="button"
                      variant={autoListenAfterResponse ? "default" : "outline"}
                      size="sm"
                      onClick={toggleAutoContinue}
                      className="text-xs h-7 px-2 gap-1"
                    >
                      <svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                        <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
                      </svg>
                      {autoListenAfterResponse ? 'è¿ç»­å¯¹è¯å¼€å¯' : 'è¿ç»­å¯¹è¯å…³é—­'}
                    </Button>
                  </FormLabel>
                  <div className="flex items-start gap-2">
                    <FormControl>
                      <Textarea 
                        placeholder="Share what you're feeling..." 
                        className="min-h-20"
                        {...field} 
                      />
                    </FormControl>
                    <div className="flex flex-col gap-2 pt-2">
                      <SpeechInput 
                        onTranscript={handleSpeechInput}
                        isListening={isListening}
                        setIsListening={setIsListening}
                        autoSubmit={true} // å¯ç”¨è‡ªåŠ¨æäº¤åŠŸèƒ½
                      />
                    </div>
                  </div>
                  <FormMessage />
                </FormItem>
              )}
            />
            
            <div className="flex gap-2">
              <Button type="submit" disabled={isLoading || isListening} className="flex-1">
                {isLoading ? 'Thinking...' : 'Send'}
              </Button>
              
              <Button 
                type="button" 
                variant="outline" 
                onClick={clearConversation}
                disabled={conversationHistory.length === 0}
              >
                Clear
              </Button>

              {isSpeaking && (
                <Button
                  type="button"
                  variant="destructive"
                  onClick={stopSpeaking}
                  title="åœæ­¢æœ—è¯»"
                >
                  åœæ­¢æœ—è¯»
                </Button>
              )}
            </div>
          </form>
        </Form>
        
        {isLoading && (
          <div className="w-full py-2">
            <Progress value={45} className="w-full" />
          </div>
        )}
      </CardContent>
      
      <CardFooter className="flex justify-between">
        <p className="text-xs text-muted-foreground">
          Powered by the Unfoldin emotional release framework and the Sedona Method
        </p>
      </CardFooter>
    </Card>
  );
} 