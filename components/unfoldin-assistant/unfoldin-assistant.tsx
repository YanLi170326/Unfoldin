'use client';

import { useState, useRef, useEffect } from 'react';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';
import * as z from 'zod';
import { atom, useAtom } from 'jotai';
import { toast } from 'sonner';
import { ExternalLink } from 'lucide-react';

import { Button } from '@/components/ui/button';
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
import { Label } from '@/components/ui/label';
import { Input } from '@/components/ui/input';
import { Form, FormControl, FormField, FormItem, FormLabel, FormMessage } from '@/components/ui/form';
import { Progress } from '@/components/ui/progress';
import { Textarea } from '@/components/ui/textarea';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import SpeechInput from './speech-input';

// Knowledge files content
import sedonaKnowledgeMap from './knowledge/sedona-knowledge-map';
import frameworkMinimal from './knowledge/framework-minimal';
import emotionMap from './knowledge/emotion-map';
import fallbackFramework from './knowledge/fallback-framework';
import shortResponseGuide from './knowledge/short-response-guide';

// Define form schema
const formSchema = z.object({
  userMessage: z.string().min(1, 'Please enter a message'),
});

// Define state atoms
const assistantResponseAtom = atom<string | null>(null);
const isLoadingAtom = atom<boolean>(false);
const conversationHistoryAtom = atom<{role: string, content: string}[]>([]);
const isListeningAtom = atom<boolean>(false);
const isSpeakingAtom = atom<boolean>(false);
const modelAtom = atom<"gpt-4o" | "gpt-3.5-turbo">("gpt-4o"); // Default to gpt-4o, fallback to gpt-3.5-turbo

export default function UnfoldinAssistant() {
  const [assistantResponse, setAssistantResponse] = useAtom(assistantResponseAtom);
  const [isLoading, setIsLoading] = useAtom(isLoadingAtom);
  const [conversationHistory, setConversationHistory] = useAtom(conversationHistoryAtom);
  const [isListening, setIsListening] = useAtom(isListeningAtom);
  const [isSpeaking, setIsSpeaking] = useAtom(isSpeakingAtom);
  const [model, setModel] = useAtom(modelAtom);
  const [autoListenAfterResponse, setAutoListenAfterResponse] = useState(false);
  
  // Unfoldin GPT System Prompt
  const systemPrompt = `# Unfoldin GPT Framework â€“ Minimal Facilitation Directive

You are an emotionally attuned AI facilitator for emotional release.
Your role is to guide users through layered emotional release sessions using a calm, grounded, and non-judgmental approach â€” never rushing, analyzing, or offering advice.

Respond in English or Chinese, matching the user's language from the beginning.
Follow a structured six-step process (Opening â†’ Reflection â†’ Acknowledgment â†’ Deepening â†’ Release â†’ Integration) using clear, minimal prompts, deliberate pauses, and emotionally attuned language.

## ğŸ” Short Response Handling

When users provide very short responses (one or two words), pay special attention:
- For responses like "ok", "maybe", "sure", "yes", etc., acknowledge their willingness to continue
- For short emotions like "sad", "angry", "anxious", identify and work with this emotion directly
- When a response is too brief to identify an emotion, say "Allow yourself to continue feeling whatever emotion is present" and then offer a gentle prompt to explore further
- Never respond robotically or with scripted text when the user gives short answers

## ğŸ§  Emotion Identification

- Actively identify emotions from the user's language, even when subtle or brief
- For unclear or very short responses, look for emotional clues in the full conversation context
- When identifying emotions, offer possibilities like "It sounds like you might be feeling [emotion]. Does that feel right?"
- If unable to identify an emotion, focus on the physical sensations ("Where do you feel this in your body?")

Use the reference file \`Imperturbability_Emotion_Map_ENHANCED.txt\` to:
- Identify the emotional category behind the user's described feeling.
- Offer facilitator-style prompts from mapped emotional states.
- Guide the user through that emotion and, when relevant, trace it back to deeper egoic attachments like security, approval, or control.

---

## ğŸ”’ Behavioral Directives

- Never analyze, interpret, or explain the user's experience.
- Do not reflect or rephrase the user's words â€” only offer emotional categories and direct prompts.
- Avoid adjectives or tonal descriptions (e.g., "gently," "softly," "patiently") that imply judgment.
- Avoid asking, "Would you like to continue?" â€” always proceed with the next facilitation step or pause.
- Use plain, stripped-down language. Stay with the feeling. Do not encourage narrative or story-making.
- When silence arises, allow space â€” don't fill it unless the user initiates.
- Avoid robotic or repetitive responses - each reply should feel fresh and responsive to the current moment.

If the user speaks Chinese, respond fully in fluent Chinese.

---

## ğŸšª Initial Engagement Guidance

If the user enters nothing or seems unsure at the beginning, initiate with:

> æ¬¢è¿ä½ ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªæƒ…ç»ªé‡Šæ”¾çš„ç©ºé—´ã€‚æˆ‘ä»¬ä¼šé€šè¿‡é—®é¢˜ä¸€å±‚å±‚å¸®ä½ è§‰å¯Ÿä¸é‡Šæ”¾å½“ä¸‹çš„æƒ…ç»ªã€‚ä½ ä¸éœ€è¦è§£é‡Šæˆ–ä¿®å¤ä»»ä½•äº‹æƒ…ï¼Œåªè¦è§‰å¯Ÿå’Œæ„Ÿå—ï¼Œå°±è¶³å¤Ÿäº†ã€‚

In English:

> Welcome. This is a space for emotional release. We'll explore and release what's emotionally present â€” step by step â€” using simple questions. You don't need to explain or fix anything. Just notice and feel.

---

## ğŸ” Release Facilitation Principles

- If the user provides very short answers, acknowledge them and say: "Allow yourself to continue feeling this. What sensations do you notice in your body?"
- If the user reports a body sensation, acknowledge only:  
  > "Let the sensation be there. Continue feeling yourself. Is there new emotion coming up on its own?"
- Do not inquire about body parts, pressure, or tension unless the user brings it up spontaneously.
- Keep language neutral and non-stylized.
- Always use the three release questions â€” without substitutes:

  1. "Can you let this go?"
  2. "Would you let this go?"
  3. "When?"

---

## ğŸ“˜ Reference Files

- \`Imperturbability_Emotion_Map_ENHANCED.txt\`: For sub-emotion categorization and matching user language to emotional states.
- \`Emotional_Release_AI_GPT_Framework_Bilingual_Fallback.md\`: For full fallback structure, multilingual versions, and extended release loops.
- \`Unfoldin_Sedona_Knowledge_Map_FINAL.md\`: Comprehensive emotional release conceptual framework, including release cycles, core wants, resistance patterns, suppression mechanics, and real-world practices.  
  ç”¨äºç†è§£æ•´ä½“é‡Šæ”¾è·¯å¾„ã€æ¸´æœ›æ ¹æºã€é˜»åŠ›ç±»å‹åŠå®è·µèŠ‚å¥ï¼Œç¡®ä¿å¼•å¯¼é£æ ¼ä¸€è‡´ã€‚

---

## ğŸ§© Framework Linkage Notice

This facilitation method follows the step-by-step structure detailed in:  
**Unfoldin_GPT_Framework_Minimal.md**

Use it to:
- Apply consistent dialogue structure across sessions.
- Maintain minimal, neutral tone with step-matching prompts.
- Align tightly with emotional release principles and user-led pacing.`;

  const form = useForm<z.infer<typeof formSchema>>({
    resolver: zodResolver(formSchema),
    defaultValues: {
      userMessage: '',
    },
  });

  // Modify the onSubmit function to no longer require API key
  const onSubmit = async (values: z.infer<typeof formSchema>) => {
    try {
      setIsLoading(true);
      
      // Add user message to conversation history
      const updatedHistory = [...conversationHistory, {role: "user", content: values.userMessage}];
      setConversationHistory(updatedHistory);
      
      // Reset form
      form.reset();
      
      // Use our backend API instead of calling OpenAI directly
      const response = await fetch('/api/openai/assistant', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          userMessage: values.userMessage,
          systemPrompt: systemPrompt,
          knowledgeContent: `
            Knowledge file 1: Unfoldin_Sedona_Knowledge_Map_FINAL.md\n\n${sedonaKnowledgeMap}
            Knowledge file 2: Unfoldin_GPT_Framework_Minimal_with_Reference.md\n\n${frameworkMinimal}
            Knowledge file 3: Imperturbability_Emotion_Map_ENHANCED.txt\n\n${emotionMap}
            Knowledge file 4: Emotional_Release_AI_GPT_Framework_Bilingual_Fallback.md\n\n${fallbackFramework}
            Knowledge file 5: Short_Response_Guide.md\n\n${shortResponseGuide}
          `,
          model: model
        }),
      });

      if (!response.ok) {
        const errorData = await response.json();
        // Check if quota exceeded or rate limited
        if (errorData.error?.message?.includes("exceeded your current quota") && model === "gpt-4o") {
          // Downgrade to gpt-3.5-turbo
          setModel("gpt-3.5-turbo");
          toast.warning("åˆ‡æ¢åˆ° GPT-3.5 æ¨¡å‹ (API é…é¢è¶…å‡º)");
          
          // Retry with gpt-3.5-turbo
          const fallbackResponse = await fetch('/api/openai/assistant', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              userMessage: values.userMessage,
              systemPrompt: systemPrompt,
              knowledgeContent: `
                Knowledge file 1: Unfoldin_Sedona_Knowledge_Map_FINAL.md\n\n${sedonaKnowledgeMap}
                Knowledge file 2: Unfoldin_GPT_Framework_Minimal_with_Reference.md\n\n${frameworkMinimal}
                Knowledge file 3: Imperturbability_Emotion_Map_ENHANCED.txt\n\n${emotionMap}
                Knowledge file 4: Emotional_Release_AI_GPT_Framework_Bilingual_Fallback.md\n\n${fallbackFramework}
                Knowledge file 5: Short_Response_Guide.md\n\n${shortResponseGuide}
              `,
              model: "gpt-3.5-turbo"
            }),
          });
          
          if (!fallbackResponse.ok) {
            const fallbackErrorData = await fallbackResponse.json();
            throw new Error(`OpenAI API error: ${fallbackErrorData.error?.message || 'Unknown error'}`);
          }
          
          const fallbackData = await fallbackResponse.json();
          const assistantMessage = fallbackData.message;
          
          // Add assistant response to conversation history
          setConversationHistory([...updatedHistory, {role: "assistant", content: assistantMessage}]);
          setAssistantResponse(assistantMessage);
          
          // Auto read response
          speakText(assistantMessage);
          
          return;
        } else {
          throw new Error(`OpenAI API error: ${errorData.error?.message || 'Unknown error'}`);
        }
      }

      const data = await response.json();
      const assistantMessage = data.message;
      
      // Add assistant response to conversation history
      setConversationHistory([...updatedHistory, {role: "assistant", content: assistantMessage}]);
      setAssistantResponse(assistantMessage);
      
      // Auto read response
      speakText(assistantMessage);
    } catch (error) {
      console.error('Error calling OpenAI API:', error);
      toast.error(`Failed to get a response: ${error instanceof Error ? error.message : 'Unknown error'}`);
    } finally {
      setIsLoading(false);
    }
  };

  // æ·»åŠ äº‹ä»¶ç›‘å¬å™¨ï¼Œç”¨äºå¤„ç†è¯­éŸ³è¯†åˆ«å®Œæˆåè‡ªåŠ¨æäº¤è¡¨å•
  useEffect(() => {
    const handleSpeechSubmit = (event: CustomEvent) => {
      // å¦‚æœæ­£åœ¨åŠ è½½å“åº”ï¼Œåˆ™ä¸å¤„ç†è¯­éŸ³æäº¤
      if (isLoading) return;
      
      // ç¡®ä¿è¡¨å•æœ‰å†…å®¹å¹¶ä¸”æäº¤
      if (form.getValues('userMessage').trim()) {
        form.handleSubmit(onSubmit)();
      }
    };

    // æ·»åŠ äº‹ä»¶ç›‘å¬
    document.addEventListener('speech-submit', handleSpeechSubmit as EventListener);
    
    // æ¸…ç†å‡½æ•°
    return () => {
      document.removeEventListener('speech-submit', handleSpeechSubmit as EventListener);
    };
  }, [form, isLoading, onSubmit]);

  // æ·»åŠ åŠ©æ‰‹å“åº”å®Œæˆåè‡ªåŠ¨å¼€å§‹ç›‘å¬çš„åŠŸèƒ½
  useEffect(() => {
    if (autoListenAfterResponse && !isLoading && assistantResponse && !isListening) {
      // å»¶è¿Ÿä¸€å°æ®µæ—¶é—´åè‡ªåŠ¨å¼€å§‹ä¸‹ä¸€æ¬¡è¯­éŸ³è¾“å…¥
      const timer = setTimeout(() => {
        setIsListening(true);
      }, 1000);
      
      return () => clearTimeout(timer);
    }
  }, [autoListenAfterResponse, isLoading, assistantResponse, isListening, setIsListening]);

  const clearConversation = () => {
    setConversationHistory([]);
    setAssistantResponse(null);
    form.reset();
    toast.success('Conversation cleared');
  };

  // è¯­éŸ³è¾“å…¥å¤„ç†å‡½æ•°
  const handleSpeechInput = (text: string) => {
    if (text.trim()) {
      form.setValue('userMessage', text);
    }
  };

  // åˆ‡æ¢è‡ªåŠ¨æŒç»­å¯¹è¯æ¨¡å¼
  const toggleAutoContinue = () => {
    setAutoListenAfterResponse(!autoListenAfterResponse);
    toast.info(autoListenAfterResponse 
      ? 'å·²å…³é—­è‡ªåŠ¨æŒç»­å¯¹è¯' 
      : 'å·²å¼€å¯è‡ªåŠ¨æŒç»­å¯¹è¯'
    );
  };

  // æ–‡å­—è½¬è¯­éŸ³åŠŸèƒ½
  const speakText = (text: string) => {
    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³åˆæˆ
    if (!('speechSynthesis' in window)) {
      console.log('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ');
      return;
    }

    // å¦‚æœå½“å‰æ­£åœ¨æœ—è¯»ï¼Œå…ˆåœæ­¢
    if (isSpeaking) {
      window.speechSynthesis.cancel();
      setIsSpeaking(false);
    }

    const utterance = new SpeechSynthesisUtterance(text);

    // æ ¹æ®æ–‡æœ¬å†…å®¹è‡ªåŠ¨æ£€æµ‹è¯­è¨€
    // ç®€å•åˆ¤æ–­ï¼šå¦‚æœåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œä½¿ç”¨ä¸­æ–‡
    if (/[\u4e00-\u9fa5]/.test(text)) {
      utterance.lang = 'zh-CN';
    } else {
      utterance.lang = 'en-US';
    }

    // è®¾ç½®è¯­é€Ÿå’ŒéŸ³é‡
    utterance.rate = 1.0;
    utterance.volume = 1.0;

    // å¼€å§‹/ç»“æŸäº‹ä»¶å¤„ç†
    utterance.onstart = () => {
      setIsSpeaking(true);
    };

    utterance.onend = () => {
      setIsSpeaking(false);
    };

    utterance.onerror = (event) => {
      console.error('Speech synthesis error:', event);
      setIsSpeaking(false);
    };

    // å¼€å§‹æœ—è¯»
    window.speechSynthesis.speak(utterance);
  };

  // åœæ­¢æœ—è¯»
  const stopSpeaking = () => {
    if ('speechSynthesis' in window) {
      window.speechSynthesis.cancel();
      setIsSpeaking(false);
    }
  };

  // åˆ‡æ¢æ¨¡å‹
  const handleModelChange = (newModel: "gpt-4o" | "gpt-3.5-turbo") => {
    setModel(newModel);
    toast.info(`å·²åˆ‡æ¢è‡³ ${newModel === "gpt-4o" ? "GPT-4o" : "GPT-3.5-turbo"} æ¨¡å‹`);
  };

  return (
    <Card className="w-full max-w-3xl mx-auto">
      <CardHeader>
        <div className="flex justify-between items-center">
          <div>
            <CardTitle>Unfoldin Emotional Release Assistant</CardTitle>
            <CardDescription>
              A guided emotional release chat
              {model === "gpt-3.5-turbo" && <span className="ml-2 text-yellow-500">(ä½¿ç”¨ GPT-3.5 æ¨¡å‹)</span>}
            </CardDescription>
          </div>
          <div className="w-40">
            <Select 
              value={model} 
              onValueChange={(value: string) => handleModelChange(value as "gpt-4o" | "gpt-3.5-turbo")}
            >
              <SelectTrigger>
                <SelectValue placeholder="é€‰æ‹©æ¨¡å‹" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="gpt-4o">GPT-4o</SelectItem>
                <SelectItem value="gpt-3.5-turbo">GPT-3.5-turbo</SelectItem>
              </SelectContent>
            </Select>
          </div>
        </div>
      </CardHeader>
      
      <CardContent className="space-y-4">
        {/* Optional: Add informational box about using the built-in API */}
        <div className="bg-neutral-50 dark:bg-neutral-900 p-4 rounded-lg border border-neutral-200 dark:border-neutral-800 text-center mb-4">
          <p className="text-sm text-muted-foreground mb-1">
            Chat with this assistant to identify, feel, and release emotions through a guided conversation.
          </p>
        </div>

        {conversationHistory.length > 0 && (
          <div className="my-4 space-y-4">
            {conversationHistory.map((message, index) => (
              <div 
                key={index}
                className={`p-3 rounded-lg ${
                  message.role === 'user' 
                    ? 'bg-primary/10 ml-8' 
                    : 'bg-secondary/20 mr-8'
                }`}
              >
                <div className="font-semibold mb-1 flex justify-between items-center">
                  <span>{message.role === 'user' ? 'You' : 'Assistant'}:</span>
                  {message.role === 'assistant' && (
                    <Button
                      variant="ghost"
                      size="icon"
                      onClick={() => speakText(message.content)}
                      title="æ’­æ”¾è¯­éŸ³"
                      className="h-6 w-6"
                    >
                      <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                        <path d="M11 5L6 9H2v6h4l5 4V5z"></path>
                        <path d="M15.54 8.46a5 5 0 0 1 0 7.07"></path>
                        <path d="M19.07 4.93a10 10 0 0 1 0 14.14"></path>
                      </svg>
                    </Button>
                  )}
                </div>
                <div className="whitespace-pre-wrap">{message.content}</div>
              </div>
            ))}
          </div>
        )}
        
        <Form {...form}>
          <form onSubmit={form.handleSubmit(onSubmit)} className="space-y-4">
            <FormField
              control={form.control}
              name="userMessage"
              render={({ field }) => (
                <FormItem>
                  <FormLabel className="flex justify-between items-center">
                    <span>Your Message</span>
                    <Button
                      type="button"
                      variant={autoListenAfterResponse ? "default" : "outline"}
                      size="sm"
                      onClick={toggleAutoContinue}
                      className="text-xs h-7 px-2 gap-1"
                    >
                      <svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                        <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
                      </svg>
                      {autoListenAfterResponse ? 'è¿ç»­å¯¹è¯å¼€å¯' : 'è¿ç»­å¯¹è¯å…³é—­'}
                    </Button>
                  </FormLabel>
                  <div className="flex items-start gap-2">
                    <FormControl>
                      <Textarea 
                        placeholder="Share what you're feeling..." 
                        className="min-h-20"
                        {...field} 
                      />
                    </FormControl>
                    <div className="flex flex-col gap-2 pt-2">
                      <SpeechInput 
                        onTranscript={handleSpeechInput}
                        isListening={isListening}
                        setIsListening={setIsListening}
                        autoSubmit={true} // å¯ç”¨è‡ªåŠ¨æäº¤åŠŸèƒ½
                      />
                    </div>
                  </div>
                  <FormMessage />
                </FormItem>
              )}
            />
            
            <div className="flex gap-2">
              <Button type="submit" disabled={isLoading || isListening} className="flex-1">
                {isLoading ? 'Thinking...' : 'Send'}
              </Button>
              
              <Button 
                type="button" 
                variant="outline" 
                onClick={clearConversation}
                disabled={conversationHistory.length === 0}
              >
                Clear
              </Button>

              {isSpeaking && (
                <Button
                  type="button"
                  variant="destructive"
                  onClick={stopSpeaking}
                  title="åœæ­¢æœ—è¯»"
                >
                  åœæ­¢æœ—è¯»
                </Button>
              )}
            </div>
          </form>
        </Form>
        
        {isLoading && (
          <div className="w-full py-2">
            <Progress value={45} className="w-full" />
          </div>
        )}
      </CardContent>
      
      <CardFooter className="flex justify-between">
        <p className="text-xs text-muted-foreground">
          Powered by the Unfoldin emotional release framework
        </p>
      </CardFooter>
    </Card>
  );
} 